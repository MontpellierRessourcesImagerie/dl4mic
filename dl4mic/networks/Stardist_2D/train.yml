user_parameters:
- name: name
  display: Name
  value: Fluo-N2DL-HeLa
  type: string
  default: new_stardist_model
  help: The name of the model. The model will be saved in a folder with this name. Using the name of an existing model will overwrite the data
- name: baseDir
  display: Base Directory
  value: /home/ltellez/Downloads/Fluo-N2DL-HeLa-training/
  type: directory
  default: E:\MRI\Fiji.app\dl4mic\models\
  help: The base-folder under which the trained model will be saved.
- name: dataSourcePath
  display: Path to the Source Data
  value: /home/ltellez/Downloads/Fluo-N2DL-HeLa-training/01/
  type: directory
  default: E:\MRI\Fiji.app\dl4mic\Stardist-data\second_source\
  help: The path to the folder containing the input images on which the model will be trained.
- name: dataTargetPath
  display: Path to the Target Data
  value: /home/ltellez/Downloads/Fluo-N2DL-HeLa-training/01_ST/SEG/
  type: directory
  default: E:\MRI\Fiji.app\dl4mic\Stardist-data\second_gt\
  help: The path to the folder containing the gt-masks on which the model will be trained.
- name: epochs
  display: Epochs
  value: 25
  type: int
  default: 200
  help: The number of epochs the network will be trained.
- name: patchSizeXY
  display: Patch Size XY
  value: 128
  type: int
  default: 512
  help: The image is divided into patches for training. Input the size of the patches (length of a side). Larger patches than 512x512 should NOT be selected for network stability.
- name: nRays
  display: Number of Rays
  value: 16
  type: int
  default: 32
  help: Set number of rays (corners) used for StarDist (for instance, a square has 4 corners).
advanced_parameters:
- name: stepsPerEpoch
  display: Steps Per Epoch
  value: 0
  type: int
  default: 0
  help: Define the number of training steps by epoch. By default this parameter is calculated so that each image / patch is seen at least once per epoch. Enter 0 to use number_of_patches / batch_size.
- name: batchSize
  display: Batch Size
  value: 4
  type: int
  default: 4
  help: This parameter describes the amount of images that are loaded into the network per step. Smaller batchsizes may improve training performance slightly but may increase training time. If the notebook crashes while loading the dataset this can be due to a too large batch size. Decrease the number in this case.
- name: gridParameter
  display: Grid Parameter
  value: 2
  type: int
  default: 2
  help: increase this number if the cells/nuclei are very large or decrease it if they are very small.
- name: validationFraction
  display: Validation Fraction
  value: 10
  type: float
  default: 10.0
  help: The fraction of your training dataset in percent, you want to use to validate the network during the training.
- name: learningRate
  display: Initial Learning Rate
  value: 0.001
  type: float
  default: 0.001
  help: The initial learning rate. The learning rate controls how much the weights of the network with are adjusted with respect to the loss gradient.
- name: resumeTraining
  display: Resume Training
  value: 0
  type: bool
  default: 0
  help: If enabled, the training will take as starting weight the weigths of the Original Model
- name: startingWeigth
  display: Original model
  value: None
  type: file
  default: None
  help: The training will take as starting weight the weigths of that h5 file
data_augmentation:
- name: augmentationFactor
  display: Augmentation Factor
  value: 4
  type: int
  default: 4
  help: Data augmentation can improve training progress by amplifying differences in the dataset. This can be useful if the available dataset is small since, in this case, it is possible that a network could quickly learn every example in the dataset (overfitting). Data augmentation is performed here via random rotations, flips, and intensity changes. Choose a factor by which you want to multiply your original dataset.
